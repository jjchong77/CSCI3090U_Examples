{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjchong77/CSCI3090U_Examples/blob/master/Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJk-2k4Q407h"
      },
      "source": [
        "# Project 1: Training a Simple Neural Network with GPU\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this project, you will create, train, and evaluate a simple neural network using both TensorFlow and PyTorch. The objective is to ensure you are comfortable with setting up a neural network and utilizing GPU acceleration for training. You will use the MNIST dataset for this project.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "1. Set up TensorFlow and PyTorch environments.\n",
        "2. Verify GPU availability.\n",
        "3. Implement a simple neural network in TensorFlow and PyTorch.\n",
        "4. Train and evaluate the models.\n",
        "5. Answer assessment questions.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Follow the steps below to complete the project. Ensure that you use a GPU to train your models.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 1: Set Up Your Environment\n",
        "\n",
        "First, install the necessary libraries. Run the following cell to install TensorFlow and PyTorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntiRM6zL407j"
      },
      "source": [
        "Provide snapshots from your environment showing:\n",
        "1) You are using a virtual environment\n",
        "2) You have installed `TensorFlow` and `PyTorch`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yfRPGB7407j"
      },
      "source": [
        "---\n",
        "\n",
        "### Step 2: Verify GPU Availability\n",
        "Check if TensorFlow and PyTorch can detect the GPU.\n",
        "\n",
        "Run the following two code blocks and show the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdyxl11Y407j"
      },
      "source": [
        "#### TensorFlow GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y_BFGfZ407k",
        "outputId": "54d55373-0d26-48c7-e6ac-cb789e908c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "GPU is available for TensorFlow!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "if gpu_devices:\n",
        "    print(\"GPU is available for TensorFlow!\")\n",
        "else:\n",
        "    print(\"No GPU found for TensorFlow.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMAz0z2e407k"
      },
      "source": [
        "#### PyTorch GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex3Pt6RS407k",
        "outputId": "4e5d75d4-2067-458a-b16c-41a44241f05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.3.0+cu121\n",
            "GPU is available for PyTorch!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available for PyTorch!\")\n",
        "else:\n",
        "    print(\"No GPU found for PyTorch.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0a5IyQ5407k"
      },
      "source": [
        "---\n",
        "\n",
        "### Step 3: Implement and Train a Simple Neural Network\n",
        "#### TensorFlow Implementation\n",
        "1. Load and preprocess the MNIST dataset.\n",
        "2. Define the neural network model.\n",
        "3. Compile the model.\n",
        "4. Train the model using the GPU.\n",
        "5. Evaluate the model.\n",
        "\n",
        "You need to complete and run the code. Show the complete output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOcF0Yuf407l",
        "outputId": "6de0ca97-8940-465e-9e37-b36c98ca19c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1594/1594 [==============================] - 6s 3ms/step - loss: 0.2848 - accuracy: 0.9196 - val_loss: 0.1365 - val_accuracy: 0.9616\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1460 - accuracy: 0.9583\n",
            "Test accuracy: 0.9583\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "with tf.device('/GPU:0'):\n",
        "    model.fit(x_train,\n",
        "    y_train,\n",
        "    validation_split=0.15)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB9Tkotz407l"
      },
      "source": [
        "#### PyTorch Implementation\n",
        "1. Load and preprocess the MNIST dataset.\n",
        "2. Define the neural network model.\n",
        "3. Define loss function and optimizer.\n",
        "4. Train the model using the GPU.\n",
        "5. Evaluate the model.\n",
        "\n",
        "You need to complete and run the code. Show the complete output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y75hOMcG407l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ea5a93-93d9-451b-edd4-601cc1a686be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 41452142.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1125942.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 9781900.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5089641.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3101\n",
            "Epoch [2/5], Loss: 0.2193\n",
            "Epoch [3/5], Loss: 0.0503\n",
            "Epoch [4/5], Loss: 0.0655\n",
            "Epoch [5/5], Loss: 0.0240\n",
            "Test Accuracy: 96.56%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdOy56Hg407m"
      },
      "source": [
        "---\n",
        "### Questions\n",
        "Answer the following questions in detail.\n",
        "\n",
        "1. What is the purpose of normalizing the input data in both TensorFlow and PyTorch implementations?\n",
        "\n",
        "Normalizing gets the data into the proper format so it can be observed properly - for instance, if we want to be calculating and predicting probability, we want the data to be between 0 and 1.\n",
        "\n",
        "2. Explain the role of the activation function relu in the neural network.\n",
        "\n",
        "Relu either outputs the input when positive, or zero if negative. It can be used to eliminate and prune data, and helps with data sparsity and efficiency.\n",
        "3. Why is it important to use GPU for training neural networks?\n",
        "\n",
        "The processes for training NNs require many calculations to be performed. For that to be done efficiently, it's better to run them in parallel simultaneously instead of sequenced one after another. A GPU has dedicateed memory to perform math and free the CPU to do other things.\n",
        "\n",
        "4. Compare the training time and accuracy of the TensorFlow and PyTorch models. Which one performed better and why?\n",
        "\n",
        "PyTorch performed better (96.56% accuracy vs Tensorflow's 95.83%). This is likely because it runs for multiple iterations to train more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGH-e1Ke407m"
      },
      "source": [
        "---\n",
        "### Submission\n",
        "Submit a link to your completed Jupyter Notebook (e.g., on GitHub (private) or Google Colab) with all the cells executed, and answers to the assessment questions included at the end of the notebook."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}